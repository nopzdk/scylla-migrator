---

- name: Install spark on scylla-migrator servers
  hosts: spark
  vars:
    home_dir: /home/ubuntu
    spark_home: /opt/spark
    spark_version: 3.5.3

  tasks: 
    #  - name: add universe repository    
    #      apt_repository:
    #        repo: deb http://ports.ubuntu.com/ubuntu-ports jammy-security universe
    #        state: present

        #- name: add universe repository
        #      become: true
        #      shell: add-apt-repository universe -y

    - name: Update apt-cache
      become: true
      apt:
        update_cache: yes

    - name: Install package dependencies.
      become: true
      package: name={{ item }} state=present
      with_items:
        - openjdk-17-jre
          #        - openjdk-17-jdk
          #        - unzip
        - python3-pip

    - name: install cqlsh
      ansible.builtin.pip:
        name: scylla-cqlsh
        state: present

          #    - name: Check that awscliv2.zip exists
          #      stat:
          #        path: awscliv2.zip
          #      register: stat_result

          #    - name: Download the awscli bundle.
          #      get_url: 
          #        url: https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip
          #        dest: "{{ home_dir }}/awscliv2.zip"
          #      when: not stat_result.stat.exists
          #      register: aws_cli_download_bundle

          #    - name: Unarchive the installer.
          #      unarchive: 
          #        src: "{{ home_dir }}/awscliv2.zip"
          #        dest: "{{ home_dir }}"
          #        remote_src: yes
        
          #      when: aws_cli_download_bundle.changed
          #      register: aws_cli_unarchive_installer

          #    - name: install awscli v2
          #      become: true
          #      shell: "{{ home_dir }}/aws/install --update"

          #    - name: Delete aws zip file
          #      ansible.builtin.file:
          #        state: absent
          #        path: "{{ home_dir }}/awscliv2.zip"

          #    - name: Delete aws install directory
          #      ansible.builtin.file:
          #        state: absent
          #        path: "{{ home_dir }}/aws"
          #

    - name: install aws-cli v2
      become: true
      community.general.snap:
        name: aws-cli
        classic: true
        channel: v2/stable


    - name: Download spark
      get_url: 
        url: https://archive.apache.org/dist/spark/spark-{{ spark_version }}/spark-{{ spark_version }}-bin-hadoop3-scala2.13.tgz
        dest: "{{ home_dir }}/spark-{{ spark_version }}-bin-hadoop3-scala2.13.tgz"

    - name: Extract spark
      ansible.builtin.unarchive:
        src: "{{ home_dir }}/spark-{{ spark_version }}-bin-hadoop3-scala2.13.tgz"
        dest: "{{ home_dir }}"
        remote_src: yes

    - name: Empty spark home
      become: true
      ansible.builtin.file:
        state: absent
        path: "{{ spark_home }}"

    - name: Move spark to /opt/spark
      become: true
      command: "mv {{ home_dir }}/spark-{{ spark_version }}-bin-hadoop3-scala2.13 {{ spark_home }}"

        #    - name: Set JAVA_HOME
        #      ansible.builtin.lineinfile:
        #        path: "{{ home_dir }}/.profile"
        #        regexp: '^JAVA_HOME='
        #        line: export JAVA_HOME=/usr/lib/jvm/java-17-openjdk-amd64

        #    - name: Add JAVA_HOME to PATH
        #      ansible.builtin.lineinfile:
        #        path: "{{ home_dir }}/.profile"
        #        regexp: '^:$JAVA_HOME'
        #        line: export PATH=$PATH:$JAVA_HOME

    - name: Set SPARK_HOME
      ansible.builtin.lineinfile:
        path: "{{ home_dir }}/.profile"
        regexp: '^:SPARK_HOME'
        line: "export SPARK_HOME={{ spark_home }}"

    - name: Add SPARK_HOME/bin to path
      ansible.builtin.lineinfile:
        path: "{{ home_dir }}/.profile"
        regexp: '^:$SPARK_HOME/bin'
        line: export PATH=$PATH:$SPARK_HOME/bin

    - name: Add SPARK_HOME/sbin to path
      ansible.builtin.lineinfile:
        path: "{{ home_dir }}/.profile"
        regexp: '^:$SPARK_HOME/sbin'
        line: export PATH=$PATH:$SPARK_HOME/sbin

    - name: Make sure slaves file exists
      become: true
      ansible.builtin.file:
        state: touch
        path: "{{ spark_home }}/conf/slaves"

    - name: Add spark nodes to slaves file
      lineinfile:
        dest: "{{ spark_home }}/conf/slaves"
        state: present
        line:  "{{ hostvars[item].ansible_host }}"
      with_items: "{{ groups['spark'] }}"

    - name: copy worker start/stop convenience scripts
      copy:
        src: "{{ item }}"
        dest: "{{ home_dir }}"
        mode: 0755
      when: inventory_hostname in groups['worker']
      with_items:
        - start-slave.sh
        - stop-slave.sh

    - name: copy template
      template:
        src: spark-env-worker-sample
        dest: "{{ home_dir }}"
      when: inventory_hostname in groups['worker']

    - name: rename spark-env
      shell: mv spark-env-worker-sample spark-env
      when: inventory_hostname in groups['worker']

- name: Install scylla migrator on master
  hosts: master
  vars:
    home_dir: /home/ubuntu
    spark_home: /opt/spark
  environment:
    JAVA_HOME: /usr/lib/jvm/java-17-openjdk-amd64
    SPARK_HOME: /opt/spark
    PATH: "/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/home/ubuntu/.local/share/coursier/bin:/usr/lib/jvm/java-17-openjdk-amd64:/opt/spark/bin:/opt/spark/sbin"

  tasks:
    - name: Create scylla-migrator directory
      ansible.builtin.file:
        path: "{{ home_dir }}/scylla-migrator"
        state: directory

    - name: copy master start/stop convenience scripts
      copy:
        src: "{{ item }}"
        dest: "{{ home_dir }}/scylla-migrator"
        mode: 0755
      with_items:
        - start-spark.sh
        - stop-spark.sh
        - start-slave.sh
        - stop-slave.sh
        - config.dynamodb.yml
    
    - name: copy template
      template:
        src: "{{ item }}"
        dest: "{{ home_dir }}/scylla-migrator"
        mode: 0755
      with_items:
        - spark-env-master-sample
        - submit-alternator-job.sh
        - submit-cql-job.sh
        - submit-cql-job-validator.sh

    - name: rename spark-env
      shell: cd "{{ home_dir }}/scylla-migrator" && mv spark-env-master-sample spark-env

    - name: change file permissions - spark-env and config.dynamodb.yml
      ansible.builtin.file:
        mode: 0655
        state: file
        path: "{{ home_dir }}/scylla-migrator/{{ item }}"
      with_items:
        - spark-env
        - config.dynamodb.yml

    - name: download scylla-migrator
      get_url:
        url: https://github.com/scylladb/scylla-migrator/releases/latest/download/scylla-migrator-assembly.jar
        dest: "{{ home_dir }}/scylla-migrator/scylla-migrator-assembly.jar"
...
